{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dfnitro3v2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('new_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CloudCover', 'HUC12', 'Latitude', 'Longitude', 'Method', 'SampleDepth',\n",
       "       'SampleId', 'WindDirection', 'WindSpeed', 'HUC12_', 'FIPS_', 'COUNTY_',\n",
       "       'STATE_', 'areaacres', 'za_mean', 'lc_11', 'lc_21', 'lc_22', 'lc_23',\n",
       "       'lc_24', 'lc_31', 'lc_41', 'lc_42', 'lc_43', 'lc_52', 'lc_71', 'lc_81',\n",
       "       'lc_82', 'lc_90', 'lc_95', 'month', 'year', 'week', 'dayofweek', 'hour',\n",
       "       'min', 'quarter', 'DO', 'TN', 'TP', 'airtemp_narr', 'precip3_narr',\n",
       "       'humidity_narr', 'cl_cover_narr', 'sfc_runoff', 'sfc_air_narr',\n",
       "       'u_wind_narr', 'v_wind_narr', 'windspeed_narr', 'wdirection_narr',\n",
       "       'precip24_narr', 'precip48_narr', 'PH', 'SA', 'of_dist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['areaacres', 'za_mean', 'lc_11', 'lc_21', 'lc_22', 'lc_23',\n",
    "       'lc_24', 'lc_31', 'lc_41', 'lc_42', 'lc_43', 'lc_52', 'lc_71', 'lc_81',\n",
    "       'lc_82', 'lc_90', 'lc_95', 'HUC12_','TN', 'airtemp_narr', 'precip3_narr',\n",
    "       'humidity_narr', 'cl_cover_narr', 'sfc_runoff', 'sfc_air_narr',\n",
    "       'u_wind_narr', 'v_wind_narr', 'windspeed_narr', 'wdirection_narr',\n",
    "       'precip24_narr', 'precip48_narr', 'of_dist', 'week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of outlier total nitrogen rows\n",
    "df2 = df[df['TN'] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['areaacres', 'za_mean', 'lc_11', 'lc_21', 'lc_22', 'lc_23', 'lc_24',\n",
       "       'lc_31', 'lc_41', 'lc_42', 'lc_43', 'lc_52', 'lc_71', 'lc_81', 'lc_82',\n",
       "       'lc_90', 'lc_95', 'HUC12_', 'TN', 'airtemp_narr', 'precip3_narr',\n",
       "       'humidity_narr', 'cl_cover_narr', 'sfc_runoff', 'sfc_air_narr',\n",
       "       'u_wind_narr', 'v_wind_narr', 'windspeed_narr', 'wdirection_narr',\n",
       "       'precip24_narr', 'precip48_narr', 'of_dist', 'week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go with the 23 features from rf first \n",
    "\n",
    "df2 = df2.loc[:,['TN','areaacres', 'za_mean', 'lc_11', 'lc_21', 'lc_24', 'lc_41', 'lc_42', 'lc_43', \n",
    "                  'lc_81', 'lc_82', 'lc_90', 'lc_95', 'of_dist', 'precip3_narr', 'humidity_narr', \n",
    "                  'cl_cover_narr', 'sfc_runoff','sfc_air_narr', 'u_wind_narr', 'windspeed_narr', \n",
    "                  'precip24_narr','HUC12_', 'week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#algorithms \n",
    "import xgboost as xgb\n",
    "\n",
    "#hyptertuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Scalers \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer, ohe, scaler\n",
    "knnimputer = KNNImputer(n_neighbors=2)\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler_std = StandardScaler()\n",
    "knn_impute_scale2 = make_pipeline(knnimputer, scaler_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46928, 32), (20112, 32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(labels = 'TN', axis = 1), df['TN'], test_size = 0.3, random_state = 0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go with the 23 features from rf\n",
    "\n",
    "#standard scaler \n",
    "ct_std = make_column_transformer(\n",
    "    (knn_impute_scale2, ['areaacres', 'za_mean', 'lc_11', 'lc_21', 'lc_24', 'lc_41', 'lc_42', 'lc_43', \n",
    "                  'lc_81', 'lc_82', 'lc_90', 'lc_95', 'of_dist', 'precip3_narr', 'humidity_narr', \n",
    "                  'cl_cover_narr', 'sfc_runoff','sfc_air_narr', 'u_wind_narr', 'windspeed_narr', \n",
    "                  'precip24_narr']),\n",
    "    (ohe, ['HUC12_', 'week']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46909, 23), (20104, 23))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop(labels = 'TN', axis = 1), df2['TN'], test_size = 0.3, random_state = 0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(xgb.XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBRegressor(random_state=0, n_jobs = -1)\n",
    "pipexgb = make_pipeline(ct_std, xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('pipeline',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer(n_neighbors=2)),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['areaacres', 'za_mean',\n",
       "                                                   'lc_11', 'lc_21', 'lc_24',\n",
       "                                                   'lc_41', 'lc_42', 'lc_43',\n",
       "                                                   'lc_81', 'lc_82', 'lc_90',\n",
       "                                                   'lc_95', 'of_dist',\n",
       "                                                   'precip3_narr',\n",
       "                                                   'humidity_narr',\n",
       "                                                   'cl_co...\n",
       "                              gpu_id=-1, importance_type='gain',\n",
       "                              interaction_constraints=None,\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=6, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=100,\n",
       "                              n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              subsample=1, tree_method=None,\n",
       "                              validate_parameters=False, verbosity=None))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipexgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipexgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8173392040208086\n",
      "0.817339477967955\n",
      "0.7654358678474267\n"
     ]
    }
   ],
   "source": [
    "#Standard Scaler\n",
    "print(r2_score(y_test, y_pred))\n",
    "print(explained_variance_score(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lc_82</td>\n",
       "      <td>0.097617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lc_11</td>\n",
       "      <td>0.072543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lc_21</td>\n",
       "      <td>0.064100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "9     lc_82    0.097617\n",
       "2     lc_11    0.072543\n",
       "3     lc_21    0.064100\n",
       "27      NaN    0.063321\n",
       "97      NaN    0.061731\n",
       "..      ...         ...\n",
       "266     NaN    0.000000\n",
       "267     NaN    0.000000\n",
       "268     NaN    0.000000\n",
       "269     NaN    0.000000\n",
       "421     NaN    0.000000\n",
       "\n",
       "[422 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X_train.columns\n",
    "#get feature importance attributed by random forest model\n",
    "importance = pd.concat([pd.Series(features),\n",
    "                       pd.Series(pipexgb['xgbregressor'].feature_importances_)], axis = 1)\n",
    "\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_csv('importances1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning 23 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "params = {}\n",
    "params['xgbregressor__max_depth'] = np.arange(0, 1100,100)\n",
    "params['xgbregressor__n_estimators'] = np.arange(0, 1000,100)\n",
    "params['xgbregressor__max_samples'] = np.arange(0, 1100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid for hypertuning\n",
    "gridRF = RandomizedSearchCV(pipexgb, params, cv = 5, random_state = 777, n_iter = 10, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('pipeline',\n",
       "                                                                               Pipeline(steps=[('knnimputer',\n",
       "                                                                                                KNNImputer(n_neighbors=2)),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['areaacres',\n",
       "                                                                                'za_mean',\n",
       "                                                                                'lc_11',\n",
       "                                                                                'lc_21',\n",
       "                                                                                'lc_24',\n",
       "                                                                                'lc_41',\n",
       "                                                                                'lc_42',\n",
       "                                                                                'lc_43',\n",
       "                                                                                'lc_81',\n",
       "                                                                                'lc_82',\n",
       "                                                                                'lc_90',\n",
       "                                                                                'lc_95',\n",
       "                                                                                'of_dist',\n",
       "                                                                                'pr...\n",
       "                                                           subsample=1,\n",
       "                                                           tree_method=None,\n",
       "                                                           validate_parameters=False,\n",
       "                                                           verbosity=None))]),\n",
       "                   param_distributions={'xgbregressor__max_depth': array([   0,  100,  200,  300,  400,  500,  600,  700,  800,  900, 1000]),\n",
       "                                        'xgbregressor__max_samples': array([   0,  100,  200,  300,  400,  500,  600,  700,  800,  900, 1000]),\n",
       "                                        'xgbregressor__n_estimators': array([  0, 100, 200, 300, 400, 500, 600, 700, 800, 900])},\n",
       "                   random_state=777, scoring='r2')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridRF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbregressor__n_estimators': 900,\n",
       " 'xgbregressor__max_samples': 800,\n",
       " 'xgbregressor__max_depth': 500}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridRF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbregressor__n_estimators</th>\n",
       "      <th>param_xgbregressor__max_samples</th>\n",
       "      <th>param_xgbregressor__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.194542</td>\n",
       "      <td>0.377798</td>\n",
       "      <td>0.393451</td>\n",
       "      <td>0.038732</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>500</td>\n",
       "      <td>{'xgbregressor__n_estimators': 900, 'xgbregres...</td>\n",
       "      <td>0.789865</td>\n",
       "      <td>0.814861</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.820931</td>\n",
       "      <td>0.843282</td>\n",
       "      <td>0.814568</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.605465</td>\n",
       "      <td>0.278139</td>\n",
       "      <td>0.394487</td>\n",
       "      <td>0.037581</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>{'xgbregressor__n_estimators': 700, 'xgbregres...</td>\n",
       "      <td>0.789865</td>\n",
       "      <td>0.814861</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.820931</td>\n",
       "      <td>0.843282</td>\n",
       "      <td>0.814568</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.939827</td>\n",
       "      <td>0.063507</td>\n",
       "      <td>0.405019</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbregressor__n_estimators': 600, 'xgbregres...</td>\n",
       "      <td>0.789865</td>\n",
       "      <td>0.814861</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.820931</td>\n",
       "      <td>0.843282</td>\n",
       "      <td>0.814568</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.121494</td>\n",
       "      <td>0.364723</td>\n",
       "      <td>0.390954</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>500</td>\n",
       "      <td>400</td>\n",
       "      <td>700</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.789865</td>\n",
       "      <td>0.814861</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.820931</td>\n",
       "      <td>0.843282</td>\n",
       "      <td>0.814568</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.133952</td>\n",
       "      <td>0.271784</td>\n",
       "      <td>0.391456</td>\n",
       "      <td>0.035891</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.789865</td>\n",
       "      <td>0.814861</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.820931</td>\n",
       "      <td>0.843282</td>\n",
       "      <td>0.814568</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      18.194542      0.377798         0.393451        0.038732   \n",
       "9      16.605465      0.278139         0.394487        0.037581   \n",
       "5      15.939827      0.063507         0.405019        0.046852   \n",
       "1      15.121494      0.364723         0.390954        0.049835   \n",
       "6      15.133952      0.271784         0.391456        0.035891   \n",
       "\n",
       "  param_xgbregressor__n_estimators param_xgbregressor__max_samples  \\\n",
       "4                              900                             800   \n",
       "9                              700                             600   \n",
       "5                              600                               0   \n",
       "1                              500                             400   \n",
       "6                              500                            1000   \n",
       "\n",
       "  param_xgbregressor__max_depth  \\\n",
       "4                           500   \n",
       "9                           300   \n",
       "5                           100   \n",
       "1                           700   \n",
       "6                           800   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'xgbregressor__n_estimators': 900, 'xgbregres...           0.789865   \n",
       "9  {'xgbregressor__n_estimators': 700, 'xgbregres...           0.789865   \n",
       "5  {'xgbregressor__n_estimators': 600, 'xgbregres...           0.789865   \n",
       "1  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.789865   \n",
       "6  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.789865   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "4           0.814861           0.803903           0.820931           0.843282   \n",
       "9           0.814861           0.803903           0.820931           0.843282   \n",
       "5           0.814861           0.803903           0.820931           0.843282   \n",
       "1           0.814861           0.803903           0.820931           0.843282   \n",
       "6           0.814861           0.803903           0.820931           0.843282   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "4         0.814568        0.017827                1  \n",
       "9         0.814568        0.017827                2  \n",
       "5         0.814568        0.017827                3  \n",
       "1         0.814568        0.017827                4  \n",
       "6         0.814568        0.017827                4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at model results\n",
    "results = pd.DataFrame(gridRF.cv_results_)\n",
    "results.sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = gridRF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8143488662585558\n",
      "0.8144045706807002\n",
      "0.7716759034731641\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred_final))\n",
    "print(explained_variance_score(y_test, y_pred_final))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lc_82</td>\n",
       "      <td>0.040281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lc_81</td>\n",
       "      <td>0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lc_11</td>\n",
       "      <td>0.007392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lc_43</td>\n",
       "      <td>0.006985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lc_21</td>\n",
       "      <td>0.006664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lc_95</td>\n",
       "      <td>0.005823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lc_41</td>\n",
       "      <td>0.003828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lc_90</td>\n",
       "      <td>0.002942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lc_42</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of_dist</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>areaacres</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>za_mean</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "27         NaN    0.678207\n",
       "97         NaN    0.123870\n",
       "76         NaN    0.056761\n",
       "9        lc_82    0.040281\n",
       "35         NaN    0.026818\n",
       "196        NaN    0.011295\n",
       "8        lc_81    0.008784\n",
       "2        lc_11    0.007392\n",
       "7        lc_43    0.006985\n",
       "3        lc_21    0.006664\n",
       "11       lc_95    0.005823\n",
       "118        NaN    0.004920\n",
       "5        lc_41    0.003828\n",
       "356        NaN    0.003128\n",
       "10       lc_90    0.002942\n",
       "6        lc_42    0.001858\n",
       "82         NaN    0.001283\n",
       "12     of_dist    0.001086\n",
       "0    areaacres    0.000667\n",
       "1      za_mean    0.000630"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X_train.columns\n",
    "#get feature importance attributed by random forest model\n",
    "importance = pd.concat([pd.Series(features),\n",
    "                       pd.Series(gridRF.best_estimator_['xgbregressor'].feature_importances_)], axis = 1)\n",
    "\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by = 'importance', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_csv('importances2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models and predictions \n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['gridRF'] = y_pred_final\n",
    "predictions_df['23feat'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat23.sav']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "grid = 'grid.sav'\n",
    "joblib.dump(gridRF, grid)\n",
    "feat23 = 'feat23.sav'\n",
    "joblib.dump(pipexgb, feat23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'tensflow'",
   "language": "python",
   "name": "tensflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

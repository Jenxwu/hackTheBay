{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#load dataframes for merging or inspection \n",
    "df = pd.read_csv('filtered_correlations.csv', index_col = 0)\n",
    "df2 = pd.read_csv('point_source_yearly.csv', index_col = 0)\n",
    "df3 = pd.read_csv('Water_FINAL.csv', index_col = 0, low_memory = False)\n",
    "df4 = pd.read_csv('model_data_enc.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#looking at interesting columns \n",
    "df_test = df2.iloc[8:,:19020].T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POINT (-75.93002800000002 39.480194)',\n",
       "       'POINT (-75.902528 39.480444)', 'POINT (-75.873639 39.466889)',\n",
       "       ..., 'POINT (-76.01420999999998 37.2313)',\n",
       "       'POINT (-75.99165000000001 37.17631)',\n",
       "       'POINT (-76.02228000000002 37.32776)'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#point source is different here \n",
    "df3['Point'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#differenet number of huc coes \n",
    "df['huc12'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['huc12_'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['HUC12_'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['HUC12'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['new_date', 'latitude', 'longitude', 'huc12_', 'areaacres', 'za_mean',\n",
       "       'lc_21', 'lc_22', 'lc_23', 'lc_24', 'lc_31', 'lc_41', 'lc_42', 'lc_43',\n",
       "       'lc_52', 'lc_71', 'lc_81', 'lc_82', 'lc_90', 'lc_95', 'month', 'year',\n",
       "       'week', 'dayofweek', 'hour', 'min', 'quarter', 'airtemp_narr',\n",
       "       'precip3_narr', 'humidity_narr', 'cl_cover_narr', 'sfc_runoff',\n",
       "       'windspeed_narr', 'wdirection_narr', 'precip24_narr', 'precip48_narr',\n",
       "       'of_dist', 'tn', 'huc12_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset looking to add in \n",
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging bryans dataframe together by huc12\n",
    "df_test = df_test.rename(columns = {'index':'ps'})\n",
    "df['ps'] = df['ps'].apply(lambda x: str(x))\n",
    "df_comb = pd.merge(df_test, df, on = 'ps')\n",
    "df_comb = df_comb.rename(columns = {'huc12': 'huc12_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to datetime \n",
    "import dateutil.parser\n",
    "df4['new_date'] = df4['new_date'].apply(lambda x :  dateutil.parser.parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting dates only after 2015-12-31\n",
    "mask16 = (df4['new_date'] > '2015-12-31') & (df4['new_date'] <= '2016-12-31')\n",
    "mask17 = (df4['new_date'] > '2016-12-31') & (df4['new_date'] <= '2017-12-31')\n",
    "mask18 = (df4['new_date'] > '2017-12-31') & (df4['new_date'] <= '2018-12-31')\n",
    "mask19 = (df4['new_date'] > '2018-12-31') & (df4['new_date'] <= '2019-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df16 = df4[mask16]\n",
    "df17 = df4[mask17]\n",
    "df18 = df4[mask18]\n",
    "df19 = df4[mask19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the nitro oxide with the huc12 number \n",
    "df_comb16 = df_comb[[2016, 'huc12_']]\n",
    "df_comb17 = df_comb[[2017, 'huc12_']]\n",
    "df_comb18 = df_comb[[2018, 'huc12_']]\n",
    "df_comb19 = df_comb[[2019, 'huc12_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Change it to string for easy matching \n",
    "df16['huc12_'] = df16['huc12_'].apply(lambda x: str(x))\n",
    "df_comb16['huc12_'] = df_comb16['huc12_'].apply(lambda x: str(x))\n",
    "\n",
    "df17['huc12_'] = df17['huc12_'].apply(lambda x: str(x))\n",
    "df_comb17['huc12_'] = df_comb17['huc12_'].apply(lambda x: str(x))\n",
    "\n",
    "df18['huc12_'] = df18['huc12_'].apply(lambda x: str(x))\n",
    "df_comb18['huc12_'] = df_comb18['huc12_'].apply(lambda x: str(x))\n",
    "\n",
    "df19['huc12_'] = df19['huc12_'].apply(lambda x: str(x))\n",
    "df_comb19['huc12_'] = df_comb19['huc12_'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge and drop duplicates created \n",
    "test1= df16.merge(df_comb16, on = 'huc12_', how = 'left')\n",
    "test1 = test1.drop_duplicates(subset=['new_date', 'huc12_'])\n",
    "\n",
    "test2= df17.merge(df_comb17, on = 'huc12_', how = 'left')\n",
    "test2 = test2.drop_duplicates(subset=['new_date', 'huc12_'])\n",
    "\n",
    "test3= df18.merge(df_comb18, on = 'huc12_', how = 'left')\n",
    "test3 = test3.drop_duplicates(subset=['new_date', 'huc12_'])\n",
    "\n",
    "test4= df19.merge(df_comb19, on = 'huc12_', how = 'left')\n",
    "test4 = test4.drop_duplicates(subset=['new_date', 'huc12_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename\n",
    "test1 = test1.rename(columns = {2016:'total Nitrogen Oxide in year'})\n",
    "test2 = test2.rename(columns = {2017:'total Nitrogen Oxide in year'})\n",
    "test3 = test3.rename(columns = {2018:'total Nitrogen Oxide in year'})\n",
    "test4 = test4.rename(columns = {2019:'total Nitrogen Oxide in year'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3755, 40), (4358, 40), (4513, 40), (4022, 40))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape \n",
    "test1.shape, test2.shape, test3.shape, test4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack on top of each other \n",
    "pieces = [test1, test2, test3, test4]\n",
    "df_final = pd.concat(pieces, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16648, 40)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file \n",
    "df_final.to_csv('final_water.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'tensflow'",
   "language": "python",
   "name": "tensflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
